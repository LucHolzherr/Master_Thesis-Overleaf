\chapter{Conclusion}
\label{sec:conclusion}
%\chapter{Einleitung}
%\label{sec:einleitung}
\section{Discussion}
In the scope of this master thesis a novel POMDP framework that reasons on multiple spatial scales is explored. Three MultiScale POMDP methods were developed to solve a robotic object search and delivery task. A low fidelity simulation was created to evaluate the algorithms. It is shown that the POMDP methods perform faster deliveries than a greedy next-best-view algorithm. The MultiScale methods differ in computation speed and reasoning abilities. The computational speedup of the MultiScale methods over solving a standard POMDP varies for the problem size. It is shown that for a small office environment where the MultiScale methods reason on two spatial layers a speedup in order of a magnitude is achieved while maintaining high solution quality. In a large office environment which requires three spatial layers a computational speedup of two magnitudes is reached for a task involving one item. For a two item task in the large environment two of the three MultiScale methods are fast enough for real-time applications.\\

MultiScale Method 01 reaches the fastest computation times at the cost of limited reasoning abilities. The lower layers neglect large parts of the state space and do not have global context about the problem available. In larger environments where three spatial layers are used this can lead to inconsistent search behaviour and suboptimal paths. MultiScale Method 02 has only slightly slower computation times than Method 01 and resolves the inconsistency problems of Method 01. The lower layers of Method 02 have access to the higher layer's value function which encodes global context about the problem and results overall in better reasoning. Method 03 further improves the reasoning abilities but at the cost of noticeably higher computation times compared to the other two MultiScale methods. The state and action space of the lower layers in Method 03 are granted more flexibility by considering more terminal states which allows to correct for inaccuracies of the higher layers. In some scenarios Method 03 has stability issues where the agent gets stuck navigating the same path back and forth. Such instabilities mostly occur for problems with a broad belief distribution.


\section{Future Work}
This thesis showed how an object search and delivery task can be solved with a POMDP high-level planner and introduced a novel MultiScale POMDP architecture. To validate the POMDP model, the algorithm should be deployed on a real robot in a large office. For such experiments the model extensions discussed in \ref{subsec:POMDP_extensions} should be further developed.\\

In the current implementation of the MultiScale POMDP framework the higher layer reward and observation models are created through manually designed open-loop policies. This is a time consuming task and can lead to inaccurate approximations. Instead, automatically created closed loop policies acting on beliefs could be investigated similar as in [\textcolor{red}{REF}]. Model approximation through closed-loop policies could potentially resolve the stability issues of Method 03 as is argued in section \ref{sec:MultiScale} \textcolor{red}{ADD PARAGRAPH IN MULTISCALE CHAPTER ABOUT THIS}. Further, it would be interesting to explore other methods to combine the spatial layers. A correction mechanism for higher layers could be included, where the higher layer models are adjusted after the lowe layer POMDPs are solved. Last but not least, the MultiScale architecture could be explored for model-free reinforcement learning where the Q-values are shared over layers similarly as the value function. 
 