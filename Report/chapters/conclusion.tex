\chapter{Conclusion}
\label{sec:conclusion}
%\chapter{Einleitung}
%\label{sec:einleitung}
\section{Discussion}
In the scope of this master thesis a novel hierarchical POMDP framework that reasons on multiple spatial scales is explored. Three Multi-Scale POMDP methods were developed to solve a robotic object search and delivery task. A low fidelity simulation was created to evaluate the algorithms. It is shown that the POMDP methods perform faster deliveries than a next-best-view algorithm. The Multi-Scale methods differ in computation speed and reasoning abilities. The computational speedup of the Multi-Scale methods over solving a standard POMDP varies for the problem size. It is shown that for a small office environment where the Multi-Scale methods reason on two spatial layers an order of magnitude speedup is achieved while maintaining high solution quality. In a large office environment which requires three spatial layers a computational speedup of two magnitudes is reached for a task involving one item. For a two item task in the large environment two of the three Multi-Scale methods are fast enough for real-time applications.\\

Multi-Scale Method 01 achieves the fastest computation times at the cost of limited reasoning abilities. The lower layers neglect large parts of the state space and do not have access to global context about the problem. In larger environments where three spatial layers are used this can lead to inconsistent search behaviour and suboptimal paths. Multi-Scale Method 02 has slightly slower computation times than Method 01 and resolves the inconsistency problems of Method 01. The lower layers of Method 02 have access to the higher layer's value function which encodes global context about the problem and results in better overall reasoning. Method 03 further improves the reasoning abilities but at the cost of noticeably higher computation times compared to the other two Multi-Scale methods. The state and action space of the lower layers of Method 03 are granted more flexibility by considering more terminal states. This enables the lower layers to correct for inaccuracies of the higher layers. In some scenarios Method 03 has stability issues where the agent gets stuck navigating the same path back and forth. Such instabilities mostly occur for problems with a broad belief distribution.


\section{Future Work}
This thesis showed how an object search and delivery task can be solved with a POMDP high-level planner and introduced a novel Multi-Scale POMDP architecture. To validate the POMDP model, the algorithm should be deployed on a real robot in a large office. For such experiments the model extensions discussed in Section \ref{subsec:POMDP_extensions} should be further developed.\\

In the current implementation of the Multi-Scale POMDP framework the higher layer reward and observation models are created through manually designed open-loop policies. This is a time consuming task and can lead to inaccurate approximations. Instead, automatically created closed loop policies acting on beliefs could be used \cite{7140035}. Model approximation through closed-loop policies could potentially resolve the stability issues of Method 03 as is argued in Section \ref{sec:Multi-Scale}. Further, it would be interesting to explore other methods to combine the spatial layers. A correction mechanism for higher layers could be included, where the higher layer models are adjusted after the lower layer POMDPs are solved. Last but not least, the Multi-Scale architecture could be explored for model-free reinforcement learning where Q-values are shared over layers in the same way that the value function is shared in Method 02 and Method 03. 
 